{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c317cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer , sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fc84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_excel('../Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249af8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/is-telehealth...\n",
       "1       2  https://insights.blackcoffer.com/how-telehealt...\n",
       "2       3  https://insights.blackcoffer.com/is-telemedici...\n",
       "3       4  https://insights.blackcoffer.com/is-telehealth...\n",
       "4       5  https://insights.blackcoffer.com/how-people-di..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25c529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = input_df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cd2831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://insights.blackcoffer.com/is-telehealth...\n",
       "1      https://insights.blackcoffer.com/how-telehealt...\n",
       "2      https://insights.blackcoffer.com/is-telemedici...\n",
       "3      https://insights.blackcoffer.com/is-telehealth...\n",
       "4      https://insights.blackcoffer.com/how-people-di...\n",
       "                             ...                        \n",
       "145    https://insights.blackcoffer.com/blockchain-fo...\n",
       "146    https://insights.blackcoffer.com/the-future-of...\n",
       "147    https://insights.blackcoffer.com/big-data-anal...\n",
       "148    https://insights.blackcoffer.com/business-anal...\n",
       "149    https://insights.blackcoffer.com/challenges-an...\n",
       "Name: URL, Length: 150, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8fc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# page=requests.get(URLs[0] , headers={\"User-Agent\": \"XY\"})\n",
    "# page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8f3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading positive words\n",
    "with open('../MasterDictionary/positive-words.txt','r') as posfile:\n",
    "    positivewords=posfile.read().lower()\n",
    "positiveWordList=positivewords.split('\\n')\n",
    "\n",
    "# Loading negative words\n",
    "with open('../MasterDictionary/negative-words.txt','r' ,  encoding=\"ISO-8859-1\") as negfile:\n",
    "    negativeword=negfile.read().lower()\n",
    "negativeWordList=negativeword.split('\\n')\n",
    "\n",
    "#Loading stop words dictionary for removing stop words\n",
    "# GENERIC\n",
    "with open('../StopWords/StopWords_Generic.txt','r' ,  encoding=\"ISO-8859-1\") as genericfile:\n",
    "    genericword=genericfile.read().lower()\n",
    "GenericWordList=genericword.split('\\n')\n",
    "\n",
    "# GENERIC LONG\n",
    "with open('../StopWords/StopWords_GenericLong.txt','r' ,  encoding=\"ISO-8859-1\") as genericlongfile:\n",
    "    genericlongword=genericlongfile.read().lower()\n",
    "GenericLongWordList=genericlongword.split('\\n')\n",
    "\n",
    "# NAMES\n",
    "with open('../StopWords/StopWords_Names.txt','r' ,  encoding=\"ISO-8859-1\") as namefile:\n",
    "    names=namefile.read().lower()\n",
    "nameList=names.split('\\n')\n",
    "\n",
    "# GEOGRAPHIC\n",
    "with open('../StopWords/StopWords_Geographic.txt','r' ,  encoding=\"ISO-8859-1\") as geofile:\n",
    "    geographics=geofile.read().lower()\n",
    "geographicList=geographics.split('\\n')\n",
    "\n",
    "# GENERIC DATES\n",
    "with open('../StopWords/StopWords_DatesandNumbers.txt','r' ,  encoding=\"ISO-8859-1\") as datefile:\n",
    "    date=datefile.read().lower()\n",
    "dateList=date.split('\\n')\n",
    "\n",
    "# CURRENCIES\n",
    "with open('../StopWords/StopWords_Currencies.txt','r' ,  encoding=\"ISO-8859-1\") as currenciesfile:\n",
    "    currencies=currenciesfile.read().lower()\n",
    "currenciesList=currencies.split('\\n')\n",
    "\n",
    "# AUDITOR\n",
    "with open('../StopWords/StopWords_Auditor.txt','r' ,  encoding=\"ISO-8859-1\") as auditfile:\n",
    "    audit=auditfile.read().lower()\n",
    "auditList=audit.split('\\n')\n",
    "# with open(stopWordsFile ,'r') as stop_words:\n",
    "#     stopWords = stop_words.read().lower()\n",
    "# stopWordList = stopWords.split('\\n')\n",
    "# stopWordList[-1:] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322d223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = list(filter(lambda token: token not in GenericWordList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in GenericLongWordList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in nameList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in geographicList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in dateList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in currenciesList, tokens))\n",
    "    filtered_words = list(filter(lambda token: token not in auditList, tokens))\n",
    "    return filtered_words\n",
    "\n",
    "def positive_score(text):\n",
    "    posword=0\n",
    "    tokenphrase = tokenizer(text)\n",
    "    for word in tokenphrase:\n",
    "        if word in positiveWordList:\n",
    "            posword+=1\n",
    "    retpos = posword\n",
    "    return retpos \n",
    "\n",
    "def negative_score(text):\n",
    "    negword=0\n",
    "    tokenphrase = tokenizer(text)\n",
    "    for word in tokenphrase:\n",
    "        if word in negativeWordList: \n",
    "            negword +=1\n",
    "    retneg = negword \n",
    "    return retneg\n",
    "\n",
    "def polarity_score(positive_score , negative_score):\n",
    "    return (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)\n",
    "\n",
    "def total_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def AverageSentenceLength (text):\n",
    "    Wordcount = len(tokenizer(text))\n",
    "    SentenceCount = len(sent_tokenize(text))\n",
    "    if SentenceCount > 0: \n",
    "        Average_Sentence_Lenght = Wordcount / SentenceCount\n",
    "    avg = Average_Sentence_Lenght\n",
    "    return round(avg)\n",
    "\n",
    "def complex_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    return complexWord\n",
    "\n",
    "def percentage_complex_word(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    complex_word_percentage = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    if len(tokens) != 0:\n",
    "        complex_word_percentage = complexWord/len(tokens)\n",
    "    \n",
    "    return complex_word_percentage\n",
    "\n",
    "def fog_index(averageSentenceLength, percentageComplexWord):\n",
    "    fogIndex = 0.4 * (averageSentenceLength + percentageComplexWord)\n",
    "    return fogIndex\n",
    "\n",
    "def subjectivity(pos,neg,total):\n",
    "    return (pos + neg)/ ((total) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e8b37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    " def avg_word_length(content):\n",
    "    return len(content.replace(' ',''))/len(content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11854d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProperNounExtractor(text):\n",
    "    count = 0\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        for (word, tag) in tagged:\n",
    "            if tag == 'PRP': # If the word is a proper noun\n",
    "                count = count + 1 \n",
    "    return(count)\n",
    "\n",
    "\n",
    "def syllable_count(content):\n",
    "    word=content.replace(' ','')\n",
    "    syllable_count=0\n",
    "    for w in word:\n",
    "        if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
    "            syllable_count=syllable_count+1\n",
    "    syllable_per_word = syllable_count/len(content.split())\n",
    "    return syllable_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c348b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_words_per_sent(content):\n",
    "    AVG_NUMBER_OF_WORDS_PER_SENTENCE = [len(l.split()) for l in re.split(r'[?!.]', content) if l.strip()]\n",
    "    AVG_NUMBER_OF_WORDS_PER_SENTENCE=sum(AVG_NUMBER_OF_WORDS_PER_SENTENCE)/len(AVG_NUMBER_OF_WORDS_PER_SENTENCE)\n",
    "    return AVG_NUMBER_OF_WORDS_PER_SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdccb4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nthe last 2 years are the most critical time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\ntelemedicine, which allows patients and doct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ntelemedicine refers to a specific set of cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nthe future of telehealth stays positive\\nto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nimagine a future where you could see any rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>\\nreconciling with the financial realities of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>\\nwhat is an investment?\\nan investment is a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>\\nquality and affordable healthcare is a visio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>\\nanalytics is a statistical scientific proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>\\nbig data\\nto begin with i shall first like t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    \\nthe last 2 years are the most critical time ...\n",
       "1    \\ntelemedicine, which allows patients and doct...\n",
       "2    \\ntelemedicine refers to a specific set of cli...\n",
       "3    \\nthe future of telehealth stays positive\\nto ...\n",
       "4    \\nimagine a future where you could see any rem...\n",
       "..                                                 ...\n",
       "144  \\nreconciling with the financial realities of ...\n",
       "145  \\nwhat is an investment?\\nan investment is a r...\n",
       "146  \\nquality and affordable healthcare is a visio...\n",
       "147  \\nanalytics is a statistical scientific proces...\n",
       "148  \\nbig data\\nto begin with i shall first like t...\n",
       "\n",
       "[149 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_data = [(open(str(i)+'.txt', \"r\", encoding=\"ISO-8859-1\")).read().lower() for i in range(2,151)]\n",
    "  \n",
    "# Create the pandas DataFrame with column name is provided explicitly\n",
    "df = pd.DataFrame(txt_data, columns=['text'])\n",
    "  \n",
    "# print dataframe.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eaceb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"text\"].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f760a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AverageSentenceLength\"] = df[\"text\"].apply(AverageSentenceLength)\n",
    "df[\"percentage_complex_word\"] = df[\"text\"].apply(percentage_complex_word)\n",
    "df[\"fog_index\"] = np.vectorize(fog_index)(df['AverageSentenceLength'],df['percentage_complex_word'])\n",
    "df[\"complex_word_count\"] = df[\"text\"].apply(complex_word_count)\n",
    "# df[\"total word count\"] = df[\"text\"].apply(total_word_count)\n",
    "df[\"total_word_count\"] = df[\"text\"].apply(total_word_count)\n",
    "df[\"positive_score\"] = df[\"text\"].apply(positive_score)\n",
    "df[\"negative_score\"] = df[\"text\"].apply(negative_score)\n",
    "df[\"polarity_score\"] = np.vectorize(polarity_score)(df['positive_score'],df['negative_score'])\n",
    "df[\"subjectivity\"] = np.vectorize(subjectivity)(df['positive_score'],df['negative_score'], df['total_word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1a8a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_word_length']=df['text'].apply(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a81d48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['personal_pronouns'] = df['text'].apply(ProperNounExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c72c7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syllable_per_word'] = df['text'].apply(syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf2df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_words_per_sent'] = df['text'].apply(avg_words_per_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f71f225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>AverageSentenceLength</th>\n",
       "      <th>percentage_complex_word</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>syllable_per_word</th>\n",
       "      <th>avg_words_per_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nthe last 2 years are the most critical time ...</td>\n",
       "      <td>[the, last, 2, years, are, the, most, critical...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.243381</td>\n",
       "      <td>8.097352</td>\n",
       "      <td>239</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>982</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>5.137500</td>\n",
       "      <td>18</td>\n",
       "      <td>2.015625</td>\n",
       "      <td>17.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\ntelemedicine, which allows patients and doct...</td>\n",
       "      <td>[telemedicine, which, allows, patients, and, d...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.300836</td>\n",
       "      <td>7.720334</td>\n",
       "      <td>540</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>0.513043</td>\n",
       "      <td>1795</td>\n",
       "      <td>0.064067</td>\n",
       "      <td>5.805461</td>\n",
       "      <td>26</td>\n",
       "      <td>2.308874</td>\n",
       "      <td>18.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ntelemedicine refers to a specific set of cli...</td>\n",
       "      <td>[telemedicine, refers, to, a, specific, set, o...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.309836</td>\n",
       "      <td>8.923934</td>\n",
       "      <td>567</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.048634</td>\n",
       "      <td>5.937535</td>\n",
       "      <td>20</td>\n",
       "      <td>2.311199</td>\n",
       "      <td>17.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nthe future of telehealth stays positive\\nto ...</td>\n",
       "      <td>[the, future, of, telehealth, stays, positive,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>10.512069</td>\n",
       "      <td>520</td>\n",
       "      <td>88</td>\n",
       "      <td>34</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>1856</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>5.718510</td>\n",
       "      <td>17</td>\n",
       "      <td>2.214129</td>\n",
       "      <td>22.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nimagine a future where you could see any rem...</td>\n",
       "      <td>[imagine, a, future, where, you, could, see, a...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>575</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1840</td>\n",
       "      <td>0.061957</td>\n",
       "      <td>5.861513</td>\n",
       "      <td>23</td>\n",
       "      <td>2.360957</td>\n",
       "      <td>18.608247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\nthe last 2 years are the most critical time ...   \n",
       "1  \\ntelemedicine, which allows patients and doct...   \n",
       "2  \\ntelemedicine refers to a specific set of cli...   \n",
       "3  \\nthe future of telehealth stays positive\\nto ...   \n",
       "4  \\nimagine a future where you could see any rem...   \n",
       "\n",
       "                                              tokens  AverageSentenceLength  \\\n",
       "0  [the, last, 2, years, are, the, most, critical...                     20   \n",
       "1  [telemedicine, which, allows, patients, and, d...                     19   \n",
       "2  [telemedicine, refers, to, a, specific, set, o...                     22   \n",
       "3  [the, future, of, telehealth, stays, positive,...                     26   \n",
       "4  [imagine, a, future, where, you, could, see, a...                     21   \n",
       "\n",
       "   percentage_complex_word  fog_index  complex_word_count  positive_score  \\\n",
       "0                 0.243381   8.097352                 239              42   \n",
       "1                 0.300836   7.720334                 540              87   \n",
       "2                 0.309836   8.923934                 567              65   \n",
       "3                 0.280172  10.512069                 520              88   \n",
       "4                 0.312500   8.525000                 575              75   \n",
       "\n",
       "   negative_score  polarity_score  total_word_count  subjectivity  \\\n",
       "0              16        0.448276               982      0.059063   \n",
       "1              28        0.513043              1795      0.064067   \n",
       "2              24        0.460674              1830      0.048634   \n",
       "3              34        0.442623              1856      0.065733   \n",
       "4              39        0.315789              1840      0.061957   \n",
       "\n",
       "   avg_word_length  personal_pronouns  syllable_per_word  avg_words_per_sent  \n",
       "0         5.137500                 18           2.015625           17.232143  \n",
       "1         5.805461                 26           2.308874           18.903226  \n",
       "2         5.937535                 20           2.311199           17.250000  \n",
       "3         5.718510                 17           2.214129           22.292683  \n",
       "4         5.861513                 23           2.360957           18.608247  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343f891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = input_df[['URL_ID', 'URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e513ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_columns = df[['positive_score','negative_score','polarity_score','subjectivity','AverageSentenceLength','percentage_complex_word','fog_index','avg_words_per_sent','complex_word_count','total_word_count','syllable_per_word','personal_pronouns','avg_word_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07cdab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df=output_df.join(extracted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f64b7853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>AverageSentenceLength</th>\n",
       "      <th>percentage_complex_word</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_words_per_sent</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>syllable_per_word</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.243381</td>\n",
       "      <td>8.097352</td>\n",
       "      <td>17.232143</td>\n",
       "      <td>239.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>2.015625</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.513043</td>\n",
       "      <td>0.064067</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.300836</td>\n",
       "      <td>7.720334</td>\n",
       "      <td>18.903226</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>2.308874</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.805461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.048634</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.309836</td>\n",
       "      <td>8.923934</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>2.311199</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.937535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.280172</td>\n",
       "      <td>10.512069</td>\n",
       "      <td>22.292683</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>2.214129</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.718510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.061957</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>18.608247</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>2.360957</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.861513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  positive_score  \\\n",
       "0       1  https://insights.blackcoffer.com/is-telehealth...            42.0   \n",
       "1       2  https://insights.blackcoffer.com/how-telehealt...            87.0   \n",
       "2       3  https://insights.blackcoffer.com/is-telemedici...            65.0   \n",
       "3       4  https://insights.blackcoffer.com/is-telehealth...            88.0   \n",
       "4       5  https://insights.blackcoffer.com/how-people-di...            75.0   \n",
       "\n",
       "   negative_score  polarity_score  subjectivity  AverageSentenceLength  \\\n",
       "0            16.0        0.448276      0.059063                   20.0   \n",
       "1            28.0        0.513043      0.064067                   19.0   \n",
       "2            24.0        0.460674      0.048634                   22.0   \n",
       "3            34.0        0.442623      0.065733                   26.0   \n",
       "4            39.0        0.315789      0.061957                   21.0   \n",
       "\n",
       "   percentage_complex_word  fog_index  avg_words_per_sent  complex_word_count  \\\n",
       "0                 0.243381   8.097352           17.232143               239.0   \n",
       "1                 0.300836   7.720334           18.903226               540.0   \n",
       "2                 0.309836   8.923934           17.250000               567.0   \n",
       "3                 0.280172  10.512069           22.292683               520.0   \n",
       "4                 0.312500   8.525000           18.608247               575.0   \n",
       "\n",
       "   total_word_count  syllable_per_word  personal_pronouns  avg_word_length  \n",
       "0             982.0           2.015625               18.0         5.137500  \n",
       "1            1795.0           2.308874               26.0         5.805461  \n",
       "2            1830.0           2.311199               20.0         5.937535  \n",
       "3            1856.0           2.214129               17.0         5.718510  \n",
       "4            1840.0           2.360957               23.0         5.861513  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3193cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel('Output Data.xlsx', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc9ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
